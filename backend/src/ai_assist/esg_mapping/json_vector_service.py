"""
ESG ë§¤í•‘ ì„œë¹„ìŠ¤ - JSON Vector Store ë²„ì „
ChromaDB ëŒ€ì‹  JSON ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì‚¬ìš© (ì™„ì „ ë¬´ë£Œ)
"""
import logging
import time
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

from .schemas import (
    ESGMappingRequest,
    ESGMappingResponse,
    ESGStandardMatch,
    ESGMappingMetadata
)
from .prompts import build_esg_mapping_prompt
from .vectorstore.json_vector_store import get_json_vector_store, SearchResult
from ..core.embeddings_factory import get_embedding_service
from ..core.gemini_client import get_gemini_client

logger = logging.getLogger(__name__)

# ì¹´í…Œê³ ë¦¬ í‘œì‹œëª… ë§¤í•‘
CATEGORY_DISPLAY_MAP = {
    "E": "Environment",
    "S": "Social", 
    "G": "Governance",
    "GENERAL": "General",
    "OTHER": "Other"
}


class JSONVectorESGMappingService:
    """
    ESG ë§¤í•‘ ì„œë¹„ìŠ¤ (JSON Vector Store)
    
    í”„ë¡œì„¸ìŠ¤:
    1. ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    2. JSON Vector Storeì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
    3. LLMìœ¼ë¡œ í›„ë³´ë“¤ì„ ë¶„ì„í•˜ê³  ì‹ ë¢°ë„ í‰ê°€
    4. ìµœì¢… ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
    
    ì¥ì :
    - ì™„ì „ ë¬´ë£Œ (DB ë¶ˆí•„ìš”)
    - ë¹ ë¥¸ ì‘ë‹µ (~3ms for 181 docs)
    - ê°„ë‹¨í•œ ë°°í¬
    """
    
    def __init__(
        self,
        json_vector_path: Optional[str] = None,
        gemini_api_key: Optional[str] = None
    ):
        """
        Args:
            json_vector_path: esg_vectors.json íŒŒì¼ ê²½ë¡œ
            gemini_api_key: Gemini API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜)
        """
        # ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (Factory íŒ¨í„´)
        logger.info("Initializing embedding service...")
        self.embeddings = get_embedding_service()
        
        # JSON Vector Store ì´ˆê¸°í™”
        logger.info("Initializing JSON Vector Store...")
        self.vector_store = get_json_vector_store(json_vector_path)
        
        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        logger.info("Initializing Gemini client...")
        self.gemini = get_gemini_client(api_key=gemini_api_key)
        
        logger.info("âœ… JSON Vector ESG Mapping Service initialized")
    
    async def map_esg(self, request: ESGMappingRequest) -> ESGMappingResponse:
        """
        ESG í‘œì¤€ ë§¤í•‘ ë©”ì¸ í•¨ìˆ˜
        
        Args:
            request: ESG ë§¤í•‘ ìš”ì²­
        
        Returns:
            ESG ë§¤í•‘ ì‘ë‹µ
        """
        start_time = time.time()
        
        logger.info(f"ğŸ” ESG Mapping started for text: '{request.text[:50]}...'")
        
        # 1. ë²¡í„° ê²€ìƒ‰
        vector_start = time.time()
        candidates = await self._vector_search(
            text=request.text,
            frameworks=request.frameworks,
            top_k=request.top_k,
            language=request.language
        )
        vector_time = time.time() - vector_start
        
        logger.info(f"  âœ“ Vector search completed: {len(candidates)} candidates ({vector_time:.3f}s)")
        
        # 2. LLM ë¶„ì„
        llm_start = time.time()
        final_matches, summary = await self._llm_analysis(
            text=request.text,
            candidates=candidates,
            min_confidence=request.min_confidence
        )
        llm_time = time.time() - llm_start
        
        logger.info(f"  âœ“ LLM analysis completed: {len(final_matches)} matches ({llm_time:.3f}s)")
        
        # 3. ì‘ë‹µ ìƒì„±
        total_time = time.time() - start_time
        
        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        if hasattr(self.embeddings, 'model_name'):
            current_embedding_model = self.embeddings.model_name  # Gemini: "gemini-embedding-001"
        elif hasattr(self.embeddings, '_model_name'):
            current_embedding_model = self.embeddings._model_name  # E5: "intfloat/multilingual-e5-base"
        else:
            current_embedding_model = "unknown"
        
        response = ESGMappingResponse(
            type="esg_mapping",
            suggestions=final_matches,
            summary=summary,
            metadata=ESGMappingMetadata(
                model_used=self.gemini.model_name,
                embedding_model=current_embedding_model,
                candidate_count=len(candidates),
                selected_count=len(final_matches),
                processing_time=round(total_time, 3),
                vector_search_time=round(vector_time, 3),
                llm_analysis_time=round(llm_time, 3)
            )
        )
        
        logger.info(f"âœ… ESG Mapping completed: {len(final_matches)} matches in {total_time:.3f}s")
        
        return response
    
    async def _vector_search(
        self,
        text: str,
        frameworks: List[str],
        top_k: int = 10,
        language: str = "ko"
    ) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        
        Args:
            text: ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
            frameworks: í”„ë ˆì„ì›Œí¬ í•„í„° (["GRI", "SASB", ...])
            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            language: ì–¸ì–´ ì½”ë“œ
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # 1. í…ìŠ¤íŠ¸ ì„ë² ë”©
        query_embedding = self.embeddings.embed_query(text)
        
        # 2. ë²¡í„° ê²€ìƒ‰
        search_results = self.vector_store.search(
            query_embedding=query_embedding,
            top_k=top_k,
            min_similarity=0.0,
            frameworks=frameworks if frameworks else None
        )
        
        # 3. ê²°ê³¼ ë³€í™˜ (VectorSearchResultëŠ” schemas.pyì™€ ë‹¤ë¥¸ ë‚´ë¶€ ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©)
        candidates = []
        for result in search_results:
            # LLMì— ì „ë‹¬í•  í˜•ì‹ (ë”•ì…”ë„ˆë¦¬)
            candidate = {
                "standard_id": result.id,
                "framework": result.framework,
                "category": result.category,
                "category_display": CATEGORY_DISPLAY_MAP.get(result.category, result.category),
                "topic": result.topic,
                "title": result.title,
                "description": result.description,
                "keywords": result.keywords,
                "similarity_score": round(result.similarity, 4)
            }
            candidates.append(candidate)
        
        return candidates
    
    async def _llm_analysis(
        self,
        text: str,
        candidates: List[Dict[str, Any]],  # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
        min_confidence: float = 0.5
    ) -> tuple[List[ESGStandardMatch], str]:
        """
        LLMìœ¼ë¡œ í›„ë³´ ë¶„ì„ ë° ì‹ ë¢°ë„ í‰ê°€
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            candidates: ë²¡í„° ê²€ìƒ‰ í›„ë³´
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„
        
        Returns:
            (ë§¤ì¹­ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ìš”ì•½)
        """
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = build_esg_mapping_prompt(
            user_text=text,
            candidates=candidates
        )
        
        # Gemini JSON í˜¸ì¶œ
        response = await asyncio.to_thread(
            self.gemini.generate_json,
            prompt=prompt
        )
        
        # DEBUG: LLM ì‘ë‹µ ë¡œê¹…
        logger.info(f"[DEBUG] LLM Response keys: {list(response.keys())}")
        matches_key = 'matches' if 'matches' in response else 'suggestions'
        logger.info(f"[DEBUG] Using key: '{matches_key}', count: {len(response.get(matches_key, []))}")
        if response.get(matches_key):
            logger.info(f"[DEBUG] First match: {response[matches_key][0]}")
        
        # ì‘ë‹µ íŒŒì‹±
        matches = []
        summary = response.get("summary", "ESG í‘œì¤€ ë§¤í•‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # LLMì´ 'matches' ë˜ëŠ” 'suggestions' ì¤‘ í•˜ë‚˜ë¡œ ë°˜í™˜
        for match_data in response.get(matches_key, []):
            # ì‹ ë¢°ë„ í•„í„°
            confidence = match_data.get("confidence", 0.0)
            if confidence < min_confidence:
                continue
            
            # ì¹´í…Œê³ ë¦¬ ì •ê·œí™”
            category = match_data.get("category", "").upper()
            category_display = CATEGORY_DISPLAY_MAP.get(category, category)
            
            match = ESGStandardMatch(
                standard_id=match_data.get("standard_id", ""),
                framework=match_data.get("framework", ""),
                category=category,
                category_display=category_display,
                topic=match_data.get("topic", ""),
                title=match_data.get("title", ""),
                description=match_data.get("description", ""),
                confidence=round(confidence, 2),
                similarity_score=match_data.get("similarity_score", 0.0),
                reasoning=match_data.get("reasoning", "LLM ë¶„ì„ ê²°ê³¼ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤."),
                keywords=match_data.get("keywords", [])
            )
            matches.append(match)
        
        return matches, summary
    
    def get_vectorstore_status(self) -> Dict[str, Any]:
        """ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ ì¡°íšŒ"""
        stats = self.vector_store.get_stats()
        
        return {
            "collection_name": "json_vector_store",
            "document_count": stats["total_documents"],
            "embedding_dimension": stats["embedding_dim"],
            "embedding_model": stats["embedding_model"],
            "memory_size_mb": round(stats["memory_size_mb"], 2),
            "file_size_mb": round(stats["file_size_mb"], 2),
        }


# ============================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# ============================================

_service_instance: Optional[JSONVectorESGMappingService] = None


def get_json_vector_esg_mapping_service(
    json_vector_path: Optional[str] = None,
    gemini_api_key: Optional[str] = None
) -> JSONVectorESGMappingService:
    """
    JSONVectorESGMappingService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Args:
        json_vector_path: JSON íŒŒì¼ ê²½ë¡œ
        gemini_api_key: Gemini API í‚¤
    
    Returns:
        JSONVectorESGMappingService ì¸ìŠ¤í„´ìŠ¤
    """
    global _service_instance
    
    if _service_instance is None:
        _service_instance = JSONVectorESGMappingService(
            json_vector_path=json_vector_path,
            gemini_api_key=gemini_api_key
        )
    
    return _service_instance


def reset_json_vector_esg_mapping_service():
    """í…ŒìŠ¤íŠ¸ìš©: ì‹±ê¸€í†¤ ë¦¬ì…‹"""
    global _service_instance
    _service_instance = None

