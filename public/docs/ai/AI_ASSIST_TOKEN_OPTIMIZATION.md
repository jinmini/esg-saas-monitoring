# Gemini API MAX_TOKENS ìµœì í™”

## ğŸ” ë¬¸ì œ ìƒí™©

### ì¦ìƒ
```
Response truncated and empty due to MAX_TOKENS limit
ERROR - Generation failed after 3 attempts
WARNING - Using fallback analysis (vector similarity only)
```

### ê·¼ë³¸ ì›ì¸

**Input í† í°ì´ ë„ˆë¬´ ë§ìŒ:**
- 10ê°œ í›„ë³´ë¥¼ LLMì— ì „ë‹¬
- ê° í›„ë³´ë§ˆë‹¤ 300ìì˜ description
- ì´ í”„ë¡¬í”„íŠ¸: **ì•½ 3000~5000 í† í°**

**Output ê³µê°„ ë¶€ì¡±:**
- `max_output_tokens=2048`
- í•˜ì§€ë§Œ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥: `2048 - (input í† í°)`
- â†’ ì‹¤ì œ ì¶œë ¥ ê³µê°„: **ì•½ 500~1000 í† í°ë§Œ ë‚¨ìŒ**
- â†’ JSON ì‘ë‹µ ìƒì„± ì¤‘ MAX_TOKENS ë„ë‹¬

---

## âœ… í•´ê²° ë°©ë²•

### ì „ëµ
1. **Input í† í° ì¤„ì´ê¸°** (í”„ë¡¬í”„íŠ¸ ìµœì í™”)
2. **Output í† í° ëŠ˜ë¦¬ê¸°** (max_output_tokens ì¦ê°€)

---

### 1. í”„ë¡¬í”„íŠ¸ ìµœì í™” (`prompts.py`)

#### A. í›„ë³´ ìˆ˜ ëŒ€í­ ê°ì†Œ

**Before:**
```python
if len(user_text) < 200:
    max_candidates = 10  # â† ë„ˆë¬´ ë§ìŒ
elif len(user_text) < 500:
    max_candidates = 7
else:
    max_candidates = 5
```

**After:**
```python
if len(user_text) < 100:
    max_candidates = 5  # ë§¤ìš° ì§§ì€ í…ìŠ¤íŠ¸
elif len(user_text) < 300:
    max_candidates = 4  # ì§§ì€ í…ìŠ¤íŠ¸
else:
    max_candidates = 3  # ê¸´ í…ìŠ¤íŠ¸
```

**íš¨ê³¼:** Input í† í° **50% ê°ì†Œ** (10ê°œ â†’ 5ê°œ)

---

#### B. Description ê¸¸ì´ ë‹¨ì¶•

**Before:**
```python
ì„¤ëª…: {meta.get('description', 'N/A')[:300]}...  # 300ì
```

**After:**
```python
description = meta.get('description', 'N/A')
if len(description) > 150:
    description = description[:150] + "..."  # 150ì
```

**íš¨ê³¼:** Input í† í° **ì¶”ê°€ 20% ê°ì†Œ**

---

#### C. ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°

**Before:**
```
ID: xxx
í”„ë ˆì„ì›Œí¬: xxx
ì¹´í…Œê³ ë¦¬: xxx
ì£¼ì œ: xxx
ì œëª©: xxx
ì„¤ëª…: xxx
í‚¤ì›Œë“œ: xxx
ìœ ì‚¬ë„: xxx
```

**After:**
```
ID: xxx
í”„ë ˆì„ì›Œí¬: xxx
ì œëª©: xxx
ì„¤ëª…: xxx
ìœ ì‚¬ë„: xxx
```

**íš¨ê³¼:** Input í† í° **ì¶”ê°€ 15% ê°ì†Œ**

---

### ì´ Input í† í° ê°ì†Œ íš¨ê³¼

| í•­ëª© | Before | After | ì ˆê° |
|-----|--------|-------|------|
| í›„ë³´ ìˆ˜ | 10ê°œ | 3-5ê°œ | -50% |
| Description | 300ì | 150ì | -50% |
| í•„ë“œ ìˆ˜ | 8ê°œ | 5ê°œ | -37.5% |
| **ì´ Input** | ~4000 í† í° | **~1200 í† í°** | **-70%** |

---

### 2. max_output_tokens ì¦ê°€ (`config.py`, `gemini_client.py`)

**Before:**
```python
GEMINI_MAX_TOKENS: int = 2048
```

**After:**
```python
GEMINI_MAX_TOKENS: int = 4096  # ESG ë§¤í•‘ JSON ì‘ë‹µì— ì¶©ë¶„í•œ ê³µê°„ í™•ë³´
```

**íš¨ê³¼:**
- Input: 1200 í† í°
- Output: 4096 í† í°
- â†’ **ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥ ì¶œë ¥: ~2900 í† í°**
- â†’ JSON ì‘ë‹µ(ì•½ 500-1000 í† í°)ì— ì¶©ë¶„í•¨ âœ…

---

### 3. í”„ë¡¬í”„íŠ¸ ì§€ì¹¨ ì—…ë°ì´íŠ¸

**Before:**
```
- ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë°˜í™˜í•˜ì„¸ìš”
```

**After:**
```
- ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ë°˜í™˜í•˜ì„¸ìš” (ê°„ê²°ì„±)
```

**íš¨ê³¼:** Output í† í° **ì¶”ê°€ ì ˆê°**

---

## ğŸ“Š í† í° ì‚¬ìš©ëŸ‰ ë¹„êµ

### Before (ë¬¸ì œ ìƒí™©)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Total Context: 8192 tokens                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  ~4000 tokens (10 candidates)        â”‚
â”‚ Output: 2048 tokens (ì„¤ì •)                  â”‚
â”‚                                             â”‚
â”‚ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥: 2048 - 4000 = OVERFLOW! âŒ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### After (ìµœì í™”)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Total Context: 8192 tokens                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  ~1200 tokens (3-5 candidates)       â”‚
â”‚ Output: 4096 tokens (ì„¤ì •)                  â”‚
â”‚                                             â”‚
â”‚ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥: ~2900 tokens âœ…             â”‚
â”‚ JSON ì‘ë‹µ ì˜ˆìƒ: ~800 tokens (ì¶©ë¶„!)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª ì˜ˆìƒ ê²°ê³¼

### Before
```
2025-10-16 22:27:24,627 - ERROR - Response truncated and empty due to MAX_TOKENS limit
2025-10-16 22:27:24,631 - WARNING - Using fallback analysis (vector similarity only)
```

### After
```
2025-10-16 22:XX:XX - DEBUG - Finish reason: FinishReason.STOP
2025-10-16 22:XX:XX - DEBUG - Extracted text via response.text: 756 chars
2025-10-16 22:XX:XX - INFO - âœ… ESG Mapping complete: 2 matches in 3.2s

Matched Standards:
  1. GRI 305-1 (0.95 confidence)
     Reasoning: Scope 1 ì§ì ‘ ë°°ì¶œëŸ‰ ë³´ê³ ì™€ ì •í™•íˆ ì¼ì¹˜
  
  2. GRI 305-5 (0.82 confidence)
     Reasoning: ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ê°ì¶• ëª©í‘œ ë‹¬ì„± ê´€ë ¨
```

---

## ğŸ“‹ ë³€ê²½ íŒŒì¼ ìš”ì•½

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|-----|---------|
| `config.py` | `GEMINI_MAX_TOKENS: 2048 â†’ 4096` |
| `gemini_client.py` | ê¸°ë³¸ê°’ `2048 â†’ 4096` |
| `prompts.py` | í›„ë³´ ìˆ˜ ê°ì†Œ (10â†’3-5), description ë‹¨ì¶• (300â†’150), í•„ë“œ ì œê±° |

---

## ğŸ’¡ Rate Limit ì˜í–¥ ë¶„ì„

### TPM (Tokens Per Minute) ê³„ì‚°

**Free Tier TPM: 250,000**

**Before:**
```
ìš”ì²­ë‹¹ í† í° = 4000 (input) + 2048 (output) = 6048
ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ = 250,000 / 6048 â‰ˆ 41 requests
```

**After:**
```
ìš”ì²­ë‹¹ í† í° = 1200 (input) + 800 (output) = 2000
ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ = 250,000 / 2000 â‰ˆ 125 requests
```

**íš¨ê³¼:** ì²˜ë¦¬ëŸ‰ **3ë°° ì¦ê°€!** ğŸš€

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

### 1. í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰
```powershell
cd backend
python scripts/ai/test_esg_mapping.py
```

### 2. í™•ì¸ ì‚¬í•­
- âœ… `Finish reason: STOP` (MAX_TOKENS ì•„ë‹˜)
- âœ… JSON íŒŒì‹± ì„±ê³µ
- âœ… 3-5ê°œ í›„ë³´ë§Œ ë¶„ì„
- âœ… ì‘ë‹µ ì‹œê°„ ë‹¨ì¶• (50s â†’ 5s ì˜ˆìƒ)

### 3. ì¶”ê°€ ìµœì í™” ê³ ë ¤
- í•„ìš”ì‹œ `temperature` ì¡°ì • (0.3 â†’ 0.1ë¡œ ë” ê²°ì •ë¡ ì )
- ìºì‹± ì¶”ê°€ (ë™ì¼í•œ í…ìŠ¤íŠ¸ ë°˜ë³µ ìš”ì²­ ë°©ì§€)

---

## ğŸ“š ì°¸ê³ 

- Gemini 2.5 Flash context window: 1,048,576 tokens
- í•˜ì§€ë§Œ ì‹¤ì œ ì‚¬ìš© ê¶Œì¥: input + output < 8192 tokens
- [Gemini API Pricing](https://ai.google.dev/pricing)

