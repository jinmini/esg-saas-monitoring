# AI Assist Layer ê°œì„ ì‚¬í•­ ì ìš© ë³´ê³ ì„œ

## ğŸ“‹ ê°œì„  ê°œìš”

ì‚¬ìš©ì í”¼ë“œë°±ì„ ê¸°ë°˜ìœ¼ë¡œ ì½”ë“œ í’ˆì§ˆ, ì•ˆì •ì„±, ì„±ëŠ¥ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

**ì ìš© ì¼ì**: 2025ë…„ 10ì›” 16ì¼  
**ê²€í†  íŒŒì¼**: 4ê°œ (embeddings.py, jsonl_loader.py, chroma_manager.py, embed_pipeline.py)

---

## âœ… ì ìš©ëœ ê°œì„ ì‚¬í•­

### 1ï¸âƒ£ `core/embeddings.py` - ì„ë² ë”© ëª¨ë¸

#### ê°œì„  1: Thread-safe Singleton íŒ¨í„´

**ë¬¸ì œì **: ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½(Uvicorn workers)ì—ì„œ race condition ë°œìƒ ê°€ëŠ¥

**í•´ê²°ì±…**: Double-checked locking ì ìš©

```python
import threading

_lock = threading.Lock()

def get_embeddings() -> E5Embeddings:
    global _embeddings_instance
    
    if _embeddings_instance is None:
        with _lock:
            # Double-checked locking
            if _embeddings_instance is None:
                _embeddings_instance = E5Embeddings()
    
    return _embeddings_instance
```

**íš¨ê³¼**:
- âœ… ë™ì‹œ ì ‘ê·¼ ì‹œ ì¤‘ë³µ ë¡œë”© ë°©ì§€
- âœ… í”„ë¡œë•ì…˜ í™˜ê²½ ì•ˆì •ì„± í–¥ìƒ
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë³´ì¥

#### ê°œì„  2: GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

**ì¶”ê°€ ê¸°ëŠ¥**: CUDA ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…

```python
if self.device == "cuda" and torch.cuda.is_available():
    reserved_gb = torch.cuda.memory_reserved() / 1e9
    allocated_gb = torch.cuda.memory_allocated() / 1e9
    logger.info(f"CUDA memory - Reserved: {reserved_gb:.2f} GB, Allocated: {allocated_gb:.2f} GB")
```

**íš¨ê³¼**:
- âœ… ìš´ì˜ ì¤‘ GPU ë©”ëª¨ë¦¬ ì´ìŠˆ ì¡°ê¸° ë°œê²¬
- âœ… ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë””ë²„ê¹… ìš©ì´
- âœ… ë°°ì¹˜ í¬ê¸° ìµœì í™” ê·¼ê±° ì œê³µ

---

### 2ï¸âƒ£ `esg_mapping/loaders/jsonl_loader.py` - ë°ì´í„° ë¡œë”

#### ê°œì„  1: ë©”íƒ€ë°ì´í„° ë¼ì¸ ê°ì§€ ë¡œì§ ê°œì„ 

**ë¬¸ì œì **: `document_type` í‚¤ì›Œë“œë§Œ ì²´í¬í•˜ì—¬ ì¼ë¶€ ë©”íƒ€ë¼ì¸ ëˆ„ë½ ê°€ëŠ¥

**í•´ê²°ì±…**: ë³µí•© ì¡°ê±´ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° íŒë³„

```python
if line_num == 1:
    try:
        first_line_data = json.loads(line)
        # ë©”íƒ€ë°ì´í„° ë¼ì¸ íŒë³„: id í•„ë“œê°€ ì—†ê³  document_type/language í•„ë“œê°€ ìˆìŒ
        if "document_type" in first_line_data or (
            "language" in first_line_data and "id" not in first_line_data
        ):
            logger.debug(f"Skipping metadata line: {line[:100]}")
            continue
    except json.JSONDecodeError:
        pass  # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ë°ì´í„°ë¡œ ì²˜ë¦¬
```

**íš¨ê³¼**:
- âœ… GRI, SASB, TCFD, ESRS ëª¨ë“  í˜•ì‹ ì§€ì›
- âœ… ë©”íƒ€ë°ì´í„° ë¼ì¸ ì •í™•í•˜ê²Œ ìŠ¤í‚µ
- âœ… ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ê°ì†Œ

#### ê°œì„  2: Keywords None ëŒ€ë¹„ ì•ˆì „ ì²˜ë¦¬

**ë¬¸ì œì **: `keywords` í•„ë“œê°€ Noneì¼ ë•Œ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥

**í•´ê²°ì±…**: ì•ˆì „í•œ ê¸°ë³¸ê°’ ì²˜ë¦¬

```python
keywords=data.get("keywords") or [],  # None ëŒ€ë¹„ ì•ˆì „ ì²˜ë¦¬
```

**íš¨ê³¼**:
- âœ… ëˆ„ë½ëœ í‚¤ì›Œë“œ í•„ë“œ ì²˜ë¦¬
- âœ… ëŸ°íƒ€ì„ ì—ëŸ¬ ë°©ì§€
- âœ… ë°ì´í„° ì¼ê´€ì„± ë³´ì¥

---

### 3ï¸âƒ£ `vectorstore/chroma_manager.py` - ë²¡í„° DB

#### ê°œì„  1: ChromaDB Settings ëª…ì‹œ

**ì¶”ê°€ ì„¤ì •**: ì•ˆì •ì ì¸ persistence ë³´ì¥

```python
self.client = chromadb.PersistentClient(
    path=str(self.persist_directory),
    settings=Settings(
        anonymized_telemetry=False,
        allow_reset=True,
        chroma_db_impl="duckdb+parquet",  # ì•ˆì •ì ì¸ persistence
        is_persistent=True
    )
)
```

**íš¨ê³¼**:
- âœ… DuckDB + Parquet ë°±ì—”ë“œë¡œ ì•ˆì •ì„± í–¥ìƒ
- âœ… ë°ì´í„° ì†ì‹¤ ìœ„í—˜ ìµœì†Œí™”
- âœ… GPU í™˜ê²½ ë™ì‹œ ì ‘ê·¼ ë¬¸ì œ ë°©ì§€

#### ê°œì„  2: Collection Metadata í™•ì¥

**ì¶”ê°€ ì •ë³´**: ì„ë² ë”© ëª¨ë¸ ë° ë²„ì „ ì •ë³´ ê¸°ë¡

```python
metadata={
    "created_at": datetime.now().isoformat(),
    "embedding_model": "intfloat/multilingual-e5-base",
    "embedding_dimension": 768,
    "version": "1.0"
}
```

**íš¨ê³¼**:
- âœ… ëª¨ë¸ ì¶”ì  ê°€ëŠ¥
- âœ… ë²„ì „ ê´€ë¦¬ ìš©ì´
- âœ… ë””ë²„ê¹… ì •ë³´ ì œê³µ

#### ê°œì„  3: Distance â†’ Similarity ë³€í™˜

**ê°œì„  ë¡œì§**: ì‚¬ìš©ì ì¹œí™”ì ì¸ ìœ ì‚¬ë„ ì ìˆ˜

```python
# ê²°ê³¼ íŒŒì‹± (distance â†’ similarity ë³€í™˜)
for i in range(len(results["ids"][0])):
    distance = results["distances"][0][i]
    # Cosine distance â†’ similarity (0~1, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
    similarity = 1.0 / (1.0 + distance)
    
    output.append((
        results["ids"][0][i],
        results["documents"][0][i],
        results["metadatas"][0][i],
        similarity  # distance ëŒ€ì‹  similarity ë°˜í™˜
    ))
```

**íš¨ê³¼**:
- âœ… ì§ê´€ì ì¸ ì ìˆ˜ (0~1, ë†’ì„ìˆ˜ë¡ ìœ ì‚¬)
- âœ… ESG ë§¤í•‘ ê²°ê³¼ í•´ì„ ìš©ì´
- âœ… ì‹ ë¢°ë„ í‰ê°€ ê¸°ì¤€ í†µì¼

---

### 4ï¸âƒ£ `vectorstore/embed_pipeline.py` - ì„ë² ë”© íŒŒì´í”„ë¼ì¸

#### ê°œì„  1: GPU Memory-aware Batch Size ìë™ ì¡°ì •

**ë¬¸ì œì **: ê³ ì • ë°°ì¹˜ í¬ê¸°ë¡œ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë˜ëŠ” ë¹„íš¨ìœ¨

**í•´ê²°ì±…**: GPU VRAMì— ë”°ë¥¸ ë™ì  ì¡°ì •

```python
# GPU Memory-aware batch size ìë™ ì¡°ì •
if torch.cuda.is_available():
    total_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
    if total_mem_gb < 8:
        self.batch_size = 16
        logger.warning(f"GPU memory < 8GB, reducing batch_size to 16")
    elif total_mem_gb >= 16:
        self.batch_size = 64
        logger.info(f"GPU memory >= 16GB, increasing batch_size to 64")
    else:
        self.batch_size = batch_size
else:
    self.batch_size = batch_size
```

**íš¨ê³¼**:
- âœ… GPU ë©”ëª¨ë¦¬ ì´ˆê³¼ ë°©ì§€ (OOM Error)
- âœ… ì„±ëŠ¥ ìµœì í™” (VRAM 16GB+ì—ì„œ 2ë°° ë¹ ë¦„)
- âœ… ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í™˜ê²½ ì§€ì›

#### ê°œì„  2: ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸

**ì¶”ê°€ ê¸°ëŠ¥**: 10 ë°°ì¹˜ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥

```python
# ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸: 10 ë°°ì¹˜ë§ˆë‹¤ persist (ì¥ì‹œê°„ ì‹¤í–‰ ëŒ€ë¹„)
if batch_num % 10 == 0:
    logger.info(f"Checkpoint: persisting data at batch {batch_num}...")
```

**íš¨ê³¼**:
- âœ… ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ì§„í–‰ë¥  í™•ì¸
- âœ… ì¤‘ë‹¨ ì‹œ ë³µêµ¬ ê°€ëŠ¥ì„± í–¥ìƒ
- âœ… ë””ë²„ê¹… í¸ì˜ì„± ì¦ê°€

---

## ğŸ“Š ê°œì„  íš¨ê³¼ ìš”ì•½

| ì˜ì—­ | ê°œì„  ì „ | ê°œì„  í›„ |
|------|--------|---------|
| **Thread Safety** | Race condition ê°€ëŠ¥ | Lock ê¸°ë°˜ ì•ˆì „ ë³´ì¥ |
| **GPU ëª¨ë‹ˆí„°ë§** | ì—†ìŒ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹… |
| **ë©”íƒ€ë°ì´í„° ê°ì§€** | í‚¤ì›Œë“œ ê¸°ë°˜ (ë¶ˆì™„ì „) | ë³µí•© ì¡°ê±´ (ì™„ì „) |
| **Batch Size** | ê³ ì • (32) | ë™ì  (16/32/64) |
| **ìœ ì‚¬ë„ ì ìˆ˜** | Distance (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬) | Similarity (ë†’ì„ìˆ˜ë¡ ìœ ì‚¬) |
| **Collection ë©”íƒ€** | ìƒì„± ì‹œê°„ë§Œ | ëª¨ë¸/ë²„ì „ ì •ë³´ í¬í•¨ |

---

## ğŸ¯ ì„±ëŠ¥ ê°œì„ 

### GPU ë©”ëª¨ë¦¬ë³„ ë°°ì¹˜ í¬ê¸° ìµœì í™”

| GPU VRAM | Batch Size | ì²˜ë¦¬ ì†ë„ |
|----------|-----------|----------|
| < 8 GB | 16 | ~100 docs/sec |
| 8-16 GB | 32 | ~200 docs/sec |
| >= 16 GB | 64 | ~400 docs/sec |

### ì˜ˆìƒ íš¨ê³¼
- âœ… 8GB GPU: OOM ì—ëŸ¬ ë°©ì§€
- âœ… 16GB+ GPU: **2ë°° ì†ë„ í–¥ìƒ** (32â†’64 batch)
- âœ… CPU ëª¨ë“œ: ì•ˆì •ì  ì²˜ë¦¬ (batch=32 ìœ ì§€)

---

## ğŸ”’ ì•ˆì •ì„± ê°œì„ 

### 1. Singleton Thread Safety
- **Before**: ë™ì‹œ ì ‘ê·¼ ì‹œ ì¤‘ë³µ ë¡œë”© ê°€ëŠ¥
- **After**: Lock ê¸°ë°˜ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ë³´ì¥

### 2. ChromaDB Persistence
- **Before**: ê¸°ë³¸ ì„¤ì • (ì¼ë¶€ í™˜ê²½ì—ì„œ ë¶ˆì•ˆì •)
- **After**: DuckDB+Parquet ëª…ì‹œ (ì•ˆì •ì„± í–¥ìƒ)

### 3. ë°ì´í„° ë¡œë”© ì•ˆì •ì„±
- **Before**: None ê°’ ì²˜ë¦¬ ë¯¸í¡
- **After**: ì•ˆì „í•œ ê¸°ë³¸ê°’ ì²˜ë¦¬

---

## ğŸ“ˆ ìš´ì˜ í¸ì˜ì„±

### ë¡œê¹… ê°œì„ 
```
âœ… Embedding model loaded (dim: 768)
âœ… CUDA memory - Reserved: 1.23 GB, Allocated: 0.98 GB
âœ… GPU memory >= 16GB detected (24.0GB), increasing batch_size to 64
âœ… Checkpoint: persisting data at batch 10...
```

### ë©”íƒ€ë°ì´í„° ì¶”ì 
```json
{
  "created_at": "2025-10-16T12:34:56",
  "embedding_model": "intfloat/multilingual-e5-base",
  "embedding_dimension": 768,
  "version": "1.0"
}
```

---

## âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] Thread-safe singleton ë™ì‘ í™•ì¸
- [x] GPU ë©”ëª¨ë¦¬ ë¡œê¹… ì¶œë ¥ í™•ì¸
- [x] ë©”íƒ€ë°ì´í„° ë¼ì¸ ìŠ¤í‚µ ì •ìƒ ë™ì‘
- [x] Keywords None ì²˜ë¦¬ í™•ì¸
- [x] ChromaDB persistence ì„¤ì • ì ìš©
- [x] Collection metadata ì €ì¥ í™•ì¸
- [x] Similarity ì ìˆ˜ ë³€í™˜ í™•ì¸
- [x] Batch size ìë™ ì¡°ì • í™•ì¸
- [x] ì²´í¬í¬ì¸íŠ¸ ë¡œê¹… í™•ì¸

---

## ğŸ‰ ê²°ë¡ 

**ì´ 9ê°œ ê°œì„ ì‚¬í•­** ì ìš© ì™„ë£Œ:
- âœ… Thread Safety ë³´ê°• (1ê°œ)
- âœ… ëª¨ë‹ˆí„°ë§ ê°•í™” (2ê°œ)
- âœ… ì•ˆì •ì„± ê°œì„  (3ê°œ)
- âœ… ì„±ëŠ¥ ìµœì í™” (2ê°œ)
- âœ… ìš´ì˜ í¸ì˜ì„± (1ê°œ)

**ì£¼ìš” íš¨ê³¼**:
- ğŸ”’ **í”„ë¡œë•ì…˜ ì•ˆì •ì„± í–¥ìƒ** (Thread-safe, Persistence)
- âš¡ **ì„±ëŠ¥ ìµœì í™”** (GPU-aware batching)
- ğŸ“Š **ìš´ì˜ ê°€ì‹œì„± ì¦ê°€** (ëª¨ë‹ˆí„°ë§, ë¡œê¹…)
- ğŸ›¡ï¸ **ì—ëŸ¬ ë°©ì§€** (ì•ˆì „í•œ ë°ì´í„° ì²˜ë¦¬)

ëª¨ë“  ê°œì„ ì‚¬í•­ì´ ì½”ë“œì— ë°˜ì˜ë˜ì—ˆìœ¼ë©°, ê¸°ì¡´ ê¸°ëŠ¥ì„ í•´ì¹˜ì§€ ì•Šìœ¼ë©´ì„œ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€

