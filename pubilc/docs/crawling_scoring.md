

# **PRD: 지능형 관련도 점수 시스템 도입 및 크롤링 고도화**

## 1. 개요 (Overview)

본 문서는 현재 크롤링 시스템의 데이터 품질 문제를 근본적으로 해결하고, 장기적으로 지속 가능한 고도화 기반을 마련하기 위한 '지능형 관련도 점수 시스템'의 도입을 목표로 한다.

현재의 단순 키워드 매칭 방식은 "하나루프"와 "하나의 루프"를 구분하지 못하고, "그리너리(기업명)"와 "그리너리(일반명사)"의 문맥을 파악하지 못하는 명백한 한계를 보이고 있다. 본 프로젝트는 이를 해결하기 위해, **명확하고 투명한 점수 기반 시스템**을 도입하고, **회사별 특성을 반영한 동적 임계값**을 적용하며, **모든 판단 과정을 추적 가능하도록** 시스템을 전면 개선한다.

## 2. 문제 정의 (Problem Statement)

1.  **부정확한 관련도 판단:** `in` 연산자를 사용한 부분 문자열 매칭으로 인해, 관련 없는 기사가 관련 있는 것으로 오분류되는 경우가 빈번하다. (예: "하나의 루프" → "하나루프")
2.  **문맥 파악의 부재:** "그리너리"와 같이 일반 명사로도 사용되는 기업명의 경우, 기사의 문맥(비즈니스/ESG vs 라이프스타일)을 고려하지 않아 대량의 노이즈 데이터가 수집된다.
3.  **일괄적인 품질 기준:** 모든 기업에 동일한 품질 기준(임계값)을 적용하여, 고유명사 기업(하나루프)과 일반명사 기업(그리너리)의 특성을 반영하지 못한다.
4.  **판단 근거의 부재 (투명성 부족):** 기사가 왜 수집되었는지, 혹은 왜 필터링되었는지 추적할 방법이 없어 문제 발생 시 원인 파악 및 개선이 어렵다.
5.  **비효율적인 DB 조회:** 기사 처리 시 매번 `Company` 정보를 DB에서 조회하여 불필요한 부하를 유발한다.

## 3. 목표 (Goals & Objectives)

*   **정확성 향상:** 수집되는 노이즈 데이터 비율을 50% 이상 감소시킨다.
*   **유연성 확보:** 회사별 특성에 맞는 차별화된 필터링 기준을 적용할 수 있는 시스템을 구축한다.
*   **투명성 및 추적성 확보:** 모든 기사의 관련도 점수와 그 상세 내역을 DB에 저장하여, 데이터 품질 분석 및 시스템 개선의 기반을 마련한다.
*   **성능 개선:** 크롤링 프로세스의 DB 조회 횟수를 최적화하여 처리 속도를 향상시킨다.

## 4. 단계별 실행 계획 (Phased Rollout)

### **Phase 1: '점수 시스템'의 정상화 (MVP)**

*   **목표:** 가장 시급한 정확성 및 투명성 문제를 해결하여 시스템의 신뢰도를 즉시 향상시킨다.

| 기능 ID | 요구사항 | 기술 명세 |
| :--- | :--- | :--- |
| **P1-F1** | **점수 저장을 위한 DB 스키마 확장** | `Article` 모델에 `relevance_score: Float`, `relevance_details: JSON`, `quality_status: String` 컬럼 추가. `Alembic` 마이그레이션 실행. |
| **P1-F2** | **회사별 동적 임계값 적용** | `Company` 모델에 `min_relevance_score: Float` 컬럼 추가 (기본값 0.6). "그리너리" 같은 특수 케이스는 0.8 등으로 설정 가능. |
| **P1-F3** | **점수 기반 `_score_article` 함수 구현** | 백분율 가중치를 폐기하고, 제안된 점수 기반 시스템으로 신규 함수 작성. <br> - **정확/부분 매칭 구분:** `re.search(r'\b' + re.escape(word) + r'\b', text)` 활용. <br> - **점수 상세 내역 생성:** `{"title_exact_match": 50, "summary_context": 20}` 와 같은 JSON 객체 생성. |
| **P1-F4** | **품질 게이트(Quality Gate) 적용** | `CrawlerService.save_articles`에서 `_score_article`을 호출. <br> - 계산된 `relevance_score`를 `company.min_relevance_score`와 비교. <br> - 결과에 따라 `quality_status`를 `'approved'` 또는 `'rejected'`로 설정. <br> - **`'rejected'` 상태의 기사는 DB에 저장하되, 일반 조회 API에서는 제외.** (데이터 분석을 위해 보존) |

### **Phase 2: '자동화'와 '최적화' 도입**

*   **목표:** 수동 개입을 줄이고 시스템의 장기적인 확장성과 성능을 확보한다.

| 기능 ID | 요구사항 | 기술 명세 |
| :--- | :--- | :--- |
| **P2-F1** | **성능 최적화를 위한 `Company` 정보 캐싱** | `CrawlerService`의 메인 크롤링 루프 시작 전, 크롤링 대상인 모든 `Company` 객체를 한 번에 조회하여 메모리(딕셔셔니)에 캐싱. 기사 처리 시 DB 조회 대신 메모리 캐시를 사용. |
| **P2-F2** | **스마트 크롤링 쿼리 전략** | `_build_enhanced_query` 함수를 수정하여, `"회사명" AND (ESG OR 탄소)` 와 유사한 효과를 내는 검색어 조합 로직 구현. (네이버 API 제약사항 내에서) |
| **P2-F3** | **`rejected` 데이터 분석을 통한 네거티브 키워드 추천** | 주기적으로 실행되는 별도의 분석 스크립트 개발. `'rejected'` 기사의 `relevance_details`를 분석하여, 특정 회사에 대해 자주 등장하는 노이즈 패턴을 찾아내고 `negative_keywords` 후보로 추천. |

### **Phase 3: '운영'과 '학습'을 위한 시스템 구축**

*   **목표:** 시스템의 건강 상태를 정량적으로 측정하고, 점진적 학습 시스템으로 발전할 기반을 마련한다.

| 기능 ID | 요구사항 | 기술 명세 |
| :--- | :--- | :--- |
| **P3-F1** | **데이터 품질 모니터링 API 개발** | `get_quality_metrics` API 엔드포인트 구현. `quality_status`를 기반으로 전체/회사별 `approved`, `rejected` 기사 수, 평균 점수 등을 집계하여 반환. |
| **P3-F2** | **'검토 요청' 상태 추가 및 관리자 UI 기반 마련** | `quality_status`에 `'review'` 상태 추가. `_score_article` 함수가 점수가 애매한 경우(예: 임계값 근처 ±5%) `'review'`로 분류하도록 로직 추가. (UI는 후속 과제) |

## 5. 제외 범위 (Out of Scope for This Version)

*   **관리자(Admin) UI 개발:** 본 PRD는 백엔드 시스템 개선에 집중한다. 관리자 UI는 별도의 프로젝트로 정의한다.
*   **실시간 머신러닝 모델 서빙:** `rejected` 데이터 분석은 배치(batch) 스크립트로 수행하며, 실시간 ML 모델 추론은 포함하지 않는다.
*   **기사 전체 본문 수집 및 분석:** 모든 분석은 네이버 API가 제공하는 `title`과 `summary`를 기반으로 한다.

---

이 PRD를 기반으로, 우리는 **Phase 1**에 모든 개발 역량을 집중하여 가장 시급한 문제를 먼저 해결해야 합니다. Phase 1이 성공적으로 완료되면, 우리 시스템은 이전과는 비교할 수 없는 수준의 데이터 품질과 안정성을 갖게 될 것입니다.